using CsvHelper;
using CsvHelper.Configuration;
using Microsoft.ML;
using Microsoft.ML.Data;
using Microsoft.ML.TorchSharp;
using System.Globalization;
using System.Text;
using static Microsoft.ML.DataOperationsCatalog;
using TorchSharp;

public class Program
{
    private static void Main(string[] args)
    {
        torch.InitializeDeviceType(DeviceType.CUDA);

        var mlContext = new MLContext()
        {
            GpuDeviceId = 0,
            FallbackToCpu = false,
        };

        if (!File.Exists(args[0]))
        {
            Console.WriteLine("File does not exist!");
            return;
        }

        var data = LoadFile(args[0]);
        data = FormatData(data);
        
        IDataView dataView = mlContext.Data.LoadFromEnumerable(data);

        var pipeline = mlContext.Transforms.Conversion.MapValueToKey(
                                            outputColumnName: "Label",
                                            inputColumnName: "Label")
                                        .Append(mlContext.MulticlassClassification.Trainers.TextClassification(
                                            labelColumnName: "Label",
                                            sentence1ColumnName: "Hash",
                                            architecture: Microsoft.ML.TorchSharp.NasBert.BertArchitecture.Roberta));

        TrainTestData trainValidationData = mlContext.Data.TrainTestSplit(dataView, testFraction: 0.2);
        ITransformer model = pipeline.Fit(trainValidationData.TrainSet);

        mlContext.Model.Save(model, trainValidationData.TrainSet.Schema, "model.zip");

        Console.WriteLine("Evaluating model performance...");
        IDataView transformedTest = model.Transform(trainValidationData.TestSet);
        
        MulticlassClassificationMetrics metrics = mlContext.MulticlassClassification.Evaluate(transformedTest);

        Console.WriteLine($"Macro Accuracy: {metrics.MacroAccuracy}");
        Console.WriteLine($"Micro Accuracy: {metrics.MicroAccuracy}");
        Console.WriteLine($"Log Loss: {metrics.LogLoss}");

        Console.WriteLine(metrics.ConfusionMatrix.GetFormattedConfusionTable());
    }

    public static IEnumerable<ModelInput> LoadFile(string filePath)
    {
        using (var reader = new StreamReader(filePath))
        {
            using (var cr = new CsvReader(reader, new CsvConfiguration(CultureInfo.InvariantCulture) { Delimiter = ",", Encoding = Encoding.UTF8 }))
            {
                while (cr.Read())
                {
                    var record = cr.GetRecord<Log>();
                    yield return new ModelInput(record.Hash, record.label.ToLower());
                }
            }
            
        }
    }

    private static IEnumerable<ModelInput> FormatData(IEnumerable<ModelInput> data)
    {
        var benignData = data.Where(x => x.Label == "benign");
        var maliciousData = data.Where(x => x.Label == "malicious");

        var datasetCount = data.Count();
        var benignCount = benignData.Count();
        var maliciousCount = maliciousData.Count();
        Console.WriteLine($"{datasetCount} records loaded");
        Console.WriteLine($"{benignCount} benign records loaded ({benignCount * 100 / datasetCount}%)");
        Console.WriteLine($"{maliciousCount} malicious records loaded ({maliciousCount * 100 / datasetCount}%)");

        var chunkSize = (maliciousCount / 3) > (benignCount / 7) ? (benignCount / 7) : (maliciousCount / 3);

        var dataset = maliciousData.Take(chunkSize * 3).Concat(benignData.Take(chunkSize * 7));

        Console.WriteLine($"{dataset.Count()} records loaded");
        return dataset;
    }
}

public class ModelInput
{
    public ModelInput(string hash, string label)
    {
        Hash = hash;
        Label = label;
    }

    [ColumnName(@"Hash")]
    public string Hash { get; set; }

    [ColumnName(@"Label")]
    public string Label { get; set; }
}

public enum Categories
{
    Benign = 0,
    Malicious = 1,
}

public class Log
{

    public string Hash {get; set;}
    public string label	{get;set;}
    public string detailed_label {get;set;}
    public string ts	{get;set;}
    public string uid	{get;set;}
    public string id_orig_h	{get;set;}
    public string id_orig_p	{get;set;}
    public string id_resp_h	{get;set;}
    public string id_resp_p	{get;set;}
    public string proto	{get;set;}
    public string service {get; set;}
    public string duration	{get;set;}
    public string orig_bytes{get;set;}
    public string resp_bytes{get;set;}
    public string conn_state{get;set;}
    public string local_orig{get;set;}
    public string local_resp{get;set;}
    public string missed_bytes{get;set;}
    public string history {get;set;}
    public string orig_pkts {get;set;}
    public string orig_ip_bytes{get;set;}
    public string resp_pkts{get;set;}
    public string resp_ip_bytes{get;set;}

}
